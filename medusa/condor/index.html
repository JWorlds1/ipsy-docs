<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="author" content="Alex Waite" />
  <title>IPSY Docs &ndash; Condor</title>
  <link rel="license" hreflang="en" href="../../copyright.html" />

  <link rel="stylesheet" type="text/css" href="/theme/css/style.css">
</head>

<body>
  <aside>
    <h1><a href="/">IPSY Docs</a></h1>
    <nav>
      <ul>

              <li><a href="/how_to_ask/">How to Ask for Help</a></li>
              <li><a href="/transferring_data/">Transferring Data</a></li>
              <li>
                <a href="/medusa/">Medusa</a>

                <ul>
                  <li>
                    <a href="/medusa/code_of_conduct/">Code of Conduct</a>
                  </li>
                  <li>
                    <a href="/medusa/accessing_medusa/">Accessing Medusa</a>
                  </li>
                  <li>
                    <a href="/medusa/data/">Data on Medusa</a>
                  </li>
                  <li>
                    <a href="/medusa/backups/">Backups</a>
                  </li>
                  <li>
                    <a class="active" href="/medusa/condor/">Condor</a>
<div id="toc"><ul><li><a class="toc-href" href="#useful commands" title="Useful Commands">Useful Commands</a></li><li><a class="toc-href" href="#documentation" title="Documentation">Documentation</a></li><li><a class="toc-href" href="#the .submit file" title="The .submit File">The .submit File</a></li><li><a class="toc-href" href="#generating a .submit file" title="Generating a .submit File">Generating a .submit File</a></li><li><a class="toc-href" href="#prioritization of jobs" title="Prioritization of Jobs">Prioritization of Jobs</a></li><li><a class="toc-href" href="#slots" title="Slots">Slots</a></li><li><a class="toc-href" href='#the "ideal" job' title='The "Ideal" Job'>The "Ideal" Job</a></li><li><a class="toc-href" href="#interactive" title="Interactive">Interactive</a></li><li><a class="toc-href" href="#fsl" title="FSL">FSL</a></li><li><a class="toc-href" href="#python" title="Python">Python</a></li><li><a class="toc-href" href="#matlab" title="Matlab">Matlab</a></li><li><a class="toc-href" href="#openblas" title="OpenBlas">OpenBlas</a></li><li><a class="toc-href" href="#dagman" title="DAGMan">DAGMan</a></li><li><a class="toc-href" href="#intel vs amd" title="Intel vs AMD">Intel vs AMD</a></li></ul></div>                  </li>
                  <li>
                    <a href="/medusa/software/">Software</a>
                  </li>
                  <li>
                    <a href="/medusa/data_center/">Data Center</a>
                  </li>
                  <li>
                    <a href="/medusa/hardware/">Hardware</a>
                  </li>
                </ul>
              </li>
              <li><a href="/labs/">Experimental Labs</a></li>
              <li><a href="/tools/">Tools</a></li>
              <li><a href="/services/">Services Provided</a></li>
              <li><a href="/printing/">Printing</a></li>
              <li><a href="/faq/">Frequently Asked Questions</a></li>
              <li><a href="/contributing/">Contributing to the Docs</a></li>
              <li><a href="/news/">News</a></li>
      </ul>
    </nav>
    <form class="searchbox" action="/search.html">
      <input type="text" name="q" id="tipue_search_input" placeholder="Search">
    </form>
  </aside>

  <main>
    <div id='content'>
<article>
  <header>
    <nav>
      <ul class="breadcrumbs">
        <li><a href="/">Home</a></li>
        <li> > <a href="/medusa/">Medusa</a></li>
        <li> > Condor</li>
      </ul>
    </nav>
    <h1>Condor</h1>
  </header>

  <div>
    <p>Medusa uses HTCondor (aka: Condor) to schedule computational jobs across the
cluster. While Condor has many features, one only needs to know a few core
commands to begin using it effectively.</p>
<div class="section" id="useful-commands">
<h2 id="useful commands">Useful Commands<a class="headerlink" href="#useful-commands" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<dl class="docutils">
<dt>List all slots (available and used) and their size</dt>
<dd><pre class="code first last literal-block">
condor_status
</pre>
</dd>
<dt>Submit a job/job cluster</dt>
<dd><pre class="code first last literal-block">
condor_submit &lt;file.submit&gt;
</pre>
</dd>
<dt>Summary of your jobs in the queue</dt>
<dd><pre class="code first last literal-block">
condor_q
</pre>
</dd>
<dt>All of your running jobs and which machine they are on</dt>
<dd><pre class="code first last literal-block">
condor_q -nobatch -run
</pre>
</dd>
<dt>All jobs from all users in the queue</dt>
<dd><pre class="code first last literal-block">
condor_q -nobatch -allusers
</pre>
</dd>
<dt>Explain why a job is in a particular state</dt>
<dd><pre class="code first last literal-block">
condor_q -better-analyze &lt;jobid&gt;
</pre>
</dd>
<dt>Remove jobs from the queue</dt>
<dd><pre class="code first last literal-block">
condor_rm &lt;username&gt;            # remove all jobs for this (your) user
condor_rm &lt;clusterid&gt;           # remove all jobs belonging to this cluster
condor_rm &lt;clusterid&gt;.&lt;jobid&gt;   # remove this specific job
</pre>
</dd>
<dt>User statistics, including priority</dt>
<dd><pre class="code first last literal-block">
condor_userprio --allusers
</pre>
</dd>
<dt>For those who are more familiar with Sun's GridEngine, condor provides <tt class="docutils literal">condor_qsub</tt>.</dt>
<dd><pre class="code first last literal-block">
condor_qsub
</pre>
</dd>
</dl>
</div>
<div class="section" id="documentation">
<h2 id="documentation">Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>The <a class="reference external" href="http://research.cs.wisc.edu/htcondor/manual/v8.4/">official Condor documentation</a> is long, but comprehensive. If you have
questions, their docs are a great resource. Pay special attention to sections
2.4, 2.5, and 2.6 of the chapter entitled <a class="reference external" href="http://research.cs.wisc.edu/htcondor/manual/v8.4/2_Users_Manual.html">Condor User Guide</a>.</p>
</div>
<div class="section" id="the-submit-file">
<h2 id="the .submit file">The .submit File<a class="headerlink" href="#the-submit-file" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>A <tt class="docutils literal">.submit</tt> file describes the jobs (commands and their arguments) that condor
will run, the environment they will run in, and the needed hardware resources
(RAM, CPU). We'll start with a short, functioning example, and then each part
will be explained.</p>
<pre class="code literal-block">
# The environment
universe       = vanilla
getenv         = True
request_cpus   = 1
request_memory = 4000

# Execution
initial_dir    = /home/user_bob/
executable     = hello_world.sh

# Job 1
arguments = "arg1" "arg2"
log       = /home/user_bob/logs/$(Cluster).$(Process).log
output    = /home/user_bob/logs/$(Cluster).$(Process).out
error     = /home/user_bob/logs/$(Cluster).$(Process).err
Queue

# Job 2
arguments = "arg1" "arg2"
log       = /home/user_bob/logs/$(Cluster).$(Process).log
output    = /home/user_bob/logs/$(Cluster).$(Process).out
error     = /home/user_bob/logs/$(Cluster).$(Process).err
Queue
</pre>
<p>The first two lines you likely will never need to change. <tt class="docutils literal">universe</tt> declares
the <em>type</em> of condor environment used, and <tt class="docutils literal">getenv</tt> tells condor to copy
environmental variables from your execution environment to the compute nodes.
Unless you <em>really</em> know what you're doing, we recommend keeping these lines
unchanged.</p>
<pre class="code literal-block">
universe = vanilla
getenv   = True
</pre>
<p>Declaring resource needs is straightforward; though do note that
<tt class="docutils literal">request_memory</tt> is in MB.</p>
<p>If you are unsure about how much memory to request: make an educated guess,
submit one job, and then check its <tt class="docutils literal">.log</tt> file, which will contain information
about memory usage while the job was running.</p>
<pre class="code literal-block">
request_cpus   = 1
request_memory = 4000
</pre>
<p><tt class="docutils literal">initial_dir</tt> is the directory that condor will <tt class="docutils literal">cd</tt> to when starting your
job. If you're using relative paths in your <tt class="docutils literal">.submit</tt> or in scripts executed
by your job, those paths are relative to this starting directory.</p>
<pre class="code literal-block">
initial_dir = /home/user_bob
</pre>
<p>Declaring the <tt class="docutils literal">executable</tt> (the program or script to be run) and the arguments
to be passed to it (such as feature flags, subject data, etc) is also
straightforward.</p>
<pre class="code literal-block">
executable = hello_world.sh
arguments = "arg1" "arg2"
</pre>
<p>Condor can generate three different types of logs per job. The <strong>log</strong> file
contains information about the job &mdash; such as duration, memory usage, the
node it ran on, etc. Any output that the executable prints will be recorded in
the <strong>output</strong> (stdout) and <strong>error</strong> (stderr) files.</p>
<p>The <tt class="docutils literal">$(Cluster)</tt> and <tt class="docutils literal">$(Process)</tt> macros supply the job ID, and are used
here to create unique log files for each job.</p>
<pre class="code literal-block">
log    = /home/user_bob/log/$(Cluster).$(Process).log
output = /home/user_bob/log/$(Cluster).$(Process).out
error  = /home/user_bob/log/$(Cluster).$(Process).err
</pre>
<p>The last line tells condor to schedule a job using the current state of all
attributes thus far defined:</p>
<pre class="code literal-block">
Queue
</pre>
<p>Then, you can change (or add) any attributes (though usually just <tt class="docutils literal">arguments</tt>,
<tt class="docutils literal">log</tt>, <tt class="docutils literal">output</tt>, and <tt class="docutils literal">error</tt>) and then add <tt class="docutils literal">Queue</tt> again. This way, you
can easily define thousands of similar jobs.</p>
<p class="todo"><strong>TODO:</strong> Use a simple system utility as the executable, so that this example
runs out-of-the-box with no need to write a hello_world.sh.</p>
</div>
<div class="section" id="generating-a-submit-file">
<h2 id="generating a .submit file">Generating a .submit File<a class="headerlink" href="#generating-a-submit-file" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>Writing <tt class="docutils literal">.submit</tt> files by hand is painful, error-prone, and does not scale &mdash;
and the entire purpose of cluster computing is scale. Thus, normal operation is
to have a script generate your <tt class="docutils literal">.submit</tt> file for you.</p>
<p>The following example shell script does the following:</p>
<ul class="simple">
<li>creates a folder for log files</li>
<li>prints to the screen the contents for a .submit file, including:<ul>
<li>the condor environment</li>
<li>the amount of CPU and RAM needed</li>
<li>the script to run (analysis.py)</li>
<li>loops over all subject csv files, scheduling one job for each file and
defining unique log files for each</li>
</ul>
</li>
</ul>
<pre class="code literal-block">
#!/bin/sh
# v1.1

cpu=1                             # CPU cores needed
mem=4000                          # expected memory usage

main_dir=/home/user_bob/tasty_Py  # path to project directory
log_dir=${main_dir}/logs          # log path
subjects_dir=${main_dir}/subjects # path to the subject files

analysis_script=${main_dir}/code/analysis.py

# check if the subjects directory exists; otherwise exit
[ ! -d "$subjects_dir" ] &amp;&amp; echo "subject dir '$subjects_dir' not found. Exiting" &amp;&amp; exit 1

# create the logs dir if it doesn't exist
[ ! -d "$log_dir" ] &amp;&amp; mkdir -p "$log_dir"

# print the .submit header
printf "# The environment
universe       = vanilla
getenv         = True
request_cpus   = $cpu
request_memory = $mem

# Execution
initial_dir    = $main_dir
executable     = $analysis_script
\n"

# create a job for each subject file
for file in ${subjects_dir}/sub*.csv ; do
    subject=${file##*/}

    printf "arguments = ${file}\n"
    printf "log       = ${log_dir}/\$(Cluster).\$(Process).${subject}.log\n"
    printf "output    = ${log_dir}/\$(Cluster).\$(Process).${subject}.out\n"
    printf "error     = ${log_dir}/\$(Cluster).\$(Process).${subject}.err\n"
    printf "Queue\n\n"
done
</pre>
<p>First, run the script and make sure that the output looks sane (if it fails with
"permission denied", you probably forgot to mark it as executable by using
<tt class="docutils literal">chmod +x</tt>).</p>
<pre class="code literal-block">
./condor_submit_gen.sh
</pre>
<p>If everything looks good, then it's time to submit the jobs to condor. The
script's output can be redirected into a file using <tt class="docutils literal">&gt;</tt></p>
<pre class="code literal-block">
./condor_submit_gen.sh &gt; the.submit
condor_submit the.submit
</pre>
<p>or directly to <tt class="docutils literal">condor_submit</tt> by using <tt class="docutils literal">|</tt>.</p>
<pre class="code literal-block">
./condor_submit_gen.sh | condor_submit
</pre>
</div>
<div class="section" id="prioritization-of-jobs">
<h2 id="prioritization of jobs">Prioritization of Jobs<a class="headerlink" href="#prioritization-of-jobs" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>Condor on Medusa is configured to assess user priority when jobs are starting.
The more compute resources consumed by the user, the more their priority is
punished (increased). This "punishment" decays back to normal over the course of
a day or two.</p>
<p>In practice, it works like this:</p>
<ul class="simple">
<li>Julie submits 10,000 jobs, each ~1 hour long</li>
<li>A day later, Jimbo submits 10 jobs</li>
<li>Jimbo's jobs wait in the queue</li>
<li>As some of Julie's jobs finish, resources are freed up</li>
<li>Both Julie's and Jimbo's jobs compete for the free resources. Jimbo's win
because his priority is low (good) and hers is very high (bad).</li>
</ul>
<p>There is also the <tt class="docutils literal">Priority Factor</tt>. Users who are <em>not</em> members of IPSY
have a modifier that punishes them even more. This way, in most cases, the jobs
of IPSY members will be preferred over those of non-IPSY users.</p>
</div>
<div class="section" id="slots">
<h2 id="slots">Slots<a class="headerlink" href="#slots" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>Medusa is configured to allow a diversity of different job sizes, while
protecting against large jobs swamping the entire cluster &mdash; and also encouraging
users to break their analysis into smaller steps.</p>
<p>The slots on Medusa are:</p>
<pre class="code literal-block">
16x    1 cpu,   4 GiB   ( 4.0 GiB/cpu)
16x    1 cpu,   6 GiB   ( 6.0 GiB/cpu)
12x    1 cpu,   5 GiB   ( 5.0 GiB/cpu)
 6x   10 cpu,  85 GiB   ( 8.5 GiB/cpu)
 2x   16 cpu, 255 GiB   (15.9 GiB/cpu)
 1x   48 cpu, 190 GiB   ( 3.9 GiB/cpu)
 1x   20 cpu,  95 GiB   ( 4.7 GiB/cpu)
 1x   16 cpu, 415 GiB   (25.9 GiB/cpu)
 1x    8 cpu,  62 GiB   ( 7.7 GiB/cpu)
 1x    4 cpu,  18 GiB   ( 4.5 GiB/cpu)
</pre>
<p>All slots larger than 1 CPU are partitionable &mdash; and thus can be broken into many
smaller slots. To illustrate: there are only 44x 1 CPU slots.  But if 500x [1
CPU &times; 4 GiB] jobs are submitted, all of the larger slots are broken up into
matching [1 CPU &times; 4 GiB] slots &mdash; resulting in a total of 231 jobs.</p>
<p>The reader may have noticed that there are 232 CPUs, and yet only 231 jobs would
be scheduled. This is because the [48 CPU &times; 190 GiB] slot (which has a RAM/CPU
ratio &lt; 4 GiB) cannot provide 4 GiB to each CPU; thus, one CPU is left idle.</p>
<p>The loss of 1 CPU for [1 CPU &times; 4 GiB] jobs is negligible. However, as an
exercise, the reader is encouraged to determine how much of the cluster would
be left idle when submitting [1 CPU &times; 5 GiB] jobs &mdash; and also [2 CPU &times; 20 GiB].</p>
</div>
<div class="section" id="the-ideal-job">
<h2 id='the "ideal" job'>The "Ideal" Job<a class="headerlink" href="#the-ideal-job" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>The "ideal" job is [1 CPU &times; 4 GiB] and runs for 10-60 minutes. Of course, not
every analysis/step can be broken down into sub-jobs that match this ideal. But
experience has shown that, with a little effort, the majority of analysis at
IPSY can.</p>
<p>The previous section (about slot sizes) neatly demonstrates why smaller jobs are
good: simply, they are more granular and thus better fit (Tetris style) into the
available compute resources.</p>
<p>The second characteristic, duration, directly affects the turnover of jobs and
how frequently compute resources become available. If 10,000x 1 hour jobs are
submitted, after awhile, a job will be finishing every minute or so (due to
normal variations across the cluster).</p>
<p>Maintaining liquidity (aka job turnover) is critical for user priority to remain
relevant (as discussed in the section Prioritization of Jobs) and ensure the
fair-distribution-of <em>and</em> timely-access-to compute resources &mdash; rather than
merely rewarding those who submit jobs first.</p>
<p>1,000 jobs lasting 1 hour each is <em>far</em> better than 100 jobs lasting 10 hours
each.</p>
</div>
<div class="section" id="interactive">
<h2 id="interactive">Interactive<a class="headerlink" href="#interactive" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>If you need more CPU or RAM than is available on the head node, you can use
Condor to gain access to an interactive shell on a node &mdash; even with a GUI.</p>
<pre class="code literal-block">
condor_submit -interactive your.submit
</pre>
</div>
<div class="section" id="fsl">
<h2 id="fsl">FSL<a class="headerlink" href="#fsl" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>FSL has been modified to directly support Condor &mdash; without the need for a
submit file. When running FSL on the head node, you can set the following
environmental variable to submit FSL computation directly to condor.</p>
<pre class="code literal-block">
FSLPARALLEL=condor
</pre>
<p class="todo"><strong>TODO:</strong> Once compute nodes can submit jobs, this needs to be better
explained and carefully reworded.</p>
<p>However, <tt class="docutils literal">feat</tt> does not parallelize the first level analysis. Thus, it is
better to create a <tt class="docutils literal">.submit</tt> file (or a script which generates one) to queue
each <tt class="docutils literal">feat</tt> call.</p>
<p>The following shell script is a good starting point to generate such a
<tt class="docutils literal">.submit</tt> file.</p>
<pre class="code literal-block">
#!/bin/sh
# v2.3

. /etc/fsl/fsl.sh            # setup FSL environment
unset FSLPARALLEL            # disable built-in FSL parallelization

cpu=1                        # CPU cores needed
mem=4000                     # expected memory usage

current_dir=$(pwd)           # path to current working directory
log_dir="${current_dir}/log" # log path
fsf_dir="${current_dir}/fsf" # path to the .fsf files

feat_cmd=$(which feat)       # path to the feat command

# check if the subjects directory exists; otherwise exit
[ ! -d "$fsf_dir" ] &amp;&amp; echo "fsf dir '$fsf_dir' not found. Exiting" &amp;&amp; exit 1

# create the logs dir if it doesn't exist
[ ! -d "$log_dir" ] &amp;&amp; mkdir -p "$log_dir"

# print header
printf "# The environment
universe       = vanilla
getenv         = True
request_cpus   = $cpu
request_memory = $mem

# Execution
initialdir     = $current_dir
executable     = $feat_cmd
\n"

# create a queue with each fsf file found in the current directory
for fsf in ${fsf_dir}/*.fsf ; do
    c_basename=`basename "$fsf"`
    c_stem=${c_basename%.fsf}

    printf "arguments = ${fsf}\n"
    printf "log       = ${log_dir}/\$(Cluster).\$(Process).${c_stem}.log\n"
    printf "output    = ${log_dir}/\$(Cluster).\$(Process).${c_stem}.out\n"
    printf "error     = ${log_dir}/\$(Cluster).\$(Process).${c_stem}.err\n"
    printf "Queue\n\n"
done
</pre>
<p>The script assumes that all <tt class="docutils literal">.fsf</tt> files for each first level analysis are
stored in a directory called <tt class="docutils literal">fsf/</tt> located under your current directory.</p>
<p>The script will output everything to the screen, which can be piped right into
<tt class="docutils literal">condor_submit</tt>.</p>
<pre class="code literal-block">
./fsf_submit.sh | condor_submit
</pre>
</div>
<div class="section" id="python">
<h2 id="python">Python<a class="headerlink" href="#python" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>The following is an example <tt class="docutils literal">.submit</tt> file to call a Python script.</p>
<pre class="code literal-block">
universe       = vanilla
getenv         = True
request_cpus   = 1
request_memory = 4000
environment    = PYTHONPATH=/usr/lib/python2.7

initialdir     = /home/user_bob/Tasty_Py
executable     = /usr/bin/python

arguments = /home/user_bob/Tasty_Py/wow.py "arg1" "arg2"
log       = /home/user_bob/Tasty_Py/log/$(Cluster).$(Process).subj1.log
output    = /home/user_bob/Tasty_Py/log/$(Cluster).$(Process).subj1.out
error     = /home/user_bob/Tasty_Py/log/$(Cluster).$(Process).subj1.err
Queue
</pre>
<p class="todo"><strong>TODO:</strong> discuss NiPype</p>
<p class="todo"><strong>TODO:</strong> discuss virtualenv</p>
</div>
<div class="section" id="matlab">
<h2 id="matlab">Matlab<a class="headerlink" href="#matlab" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>The following is an example <tt class="docutils literal">.submit</tt> file to call Matlab</p>
<pre class="code literal-block">
universe       = vanilla
getenv         = True
request_cpus   = 1
request_memory = 8000

initialdir     = /home/user_bob/Wicked_Analysis
executable     = /usr/bin/matlab

arguments = -singleCompThread -r Gravity(1)
log       = /home/user_bob/Wicked_Analysis/log/$(Cluster).$(Process).subj1.log
output    = /home/user_bob/Wicked_Analysis/log/$(Cluster).$(Process).subj1.out
error     = /home/user_bob/Wicked_Analysis/log/$(Cluster).$(Process).subj1.err
Queue
</pre>
<p>By default, Matlab will use all available CPUs. The only effective way to
control Matlab is to use the <tt class="docutils literal"><span class="pre">-singleCompthread</span></tt> option, which will limit it
to a single CPU. There is a <a class="reference external" href="https://www.mathworks.com/help/matlab/ref/maxnumcompthreads.html">maxNumCompThreads()</a> function, but it is
deprecated and is considered unreliable.</p>
<p class="note"><strong>NOTE:</strong> With the increase in the number of available campus toolbox
licenses, it is no longer necessary to restrict Matlab jobs to specific
compute nodes.</p>
</div>
<div class="section" id="openblas">
<h2 id="openblas">OpenBlas<a class="headerlink" href="#openblas" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>OpenBlas automatically scales up to use all the CPUs on a system. For example,
to limit it two CPUs, set the following environmental variable.</p>
<pre class="code literal-block">
OMP_NUM_THREADS=2
</pre>
</div>
<div class="section" id="dagman">
<h2 id="dagman">DAGMan<a class="headerlink" href="#dagman" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p class="todo"><strong>TODO:</strong> discuss DAGMan</p>
</div>
<div class="section" id="intel-vs-amd">
<h2 id="intel vs amd">Intel vs AMD<a class="headerlink" href="#intel-vs-amd" title="Permalink to this headline"><i class="icon-link"></i></a></h2>
<p>Our cluster's Intel nodes have the fastest single thread performance. If you
have very few, single CPU jobs and need them to execute as fast as possible,
then restricting your jobs to the nodes with Intel CPUs can be beneficial.</p>
<p>The nodes are configured to advertise their CPU vendor, so it is easy to
constrain according to CPU type. Add the following to your <tt class="docutils literal">.submit</tt> file.</p>
<pre class="code literal-block">
Requirements = CPUVendor == "INTEL"
</pre>
<p>Or, to <em>prefer</em> Intel CPUs but not <em>require</em> them</p>
<pre class="code literal-block">
Rank = CPUVendor == "INTEL"
</pre>
</div>

  </div>
</article>
    </div>

    <footer>
      <p><small>
        content licensed <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">cc-by-sa</a>
        <span class='break'>—</span> ©2012–2018 Alex Waite <span class='break'>—</span>
        unless <a rel="license" href='/copyright.html'>indicated otherwise</a>
      </small></p>
    </footer>
  </main>
</body>
</html>